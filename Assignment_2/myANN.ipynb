{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRWZvulj7E2m"
   },
   "source": [
    "Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ohdM7QL17iXR"
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GroupKFold\n",
    "from scipy.stats import uniform, randint, expon\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhM2OoE97B7v"
   },
   "source": [
    "Implementing My ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QxJY3Fj_45hn"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "        \"\"\"Computes sigmoid function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : int or numpy.array\n",
    "            Real numbers to compute sigmoid function on\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.array\n",
    "            Result of sigmoid function for each element of x\n",
    "        \"\"\"\n",
    "        return(1/(1+np.exp(-x)))\n",
    "\n",
    "def relu(x):\n",
    "        \"\"\"Computes relu function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : int or numpy.array\n",
    "            Real numbers to compute relu function on\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.array\n",
    "            Result of relu function for each element of x\n",
    "        \"\"\"\n",
    "        return(np.clip(x, a_min = 0, a_max = None))\n",
    "\n",
    "class ANN(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A class used to represent an Artificial Neural Network\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_input : int\n",
    "        a integer to indicate number of input units (features)\n",
    "    n_hidden : tuple\n",
    "        a tuple containing a maximum of 2 integers indicatng size of (number of units in) each hidden layer (default (5,))\n",
    "    seed : int\n",
    "        the random state to use for initializing weights and data shuffle (default random)\n",
    "    act_h : str\n",
    "        the activation function to use, on of 'sigmoid' or 'relu' (default 'relu')\n",
    "    n_output : int\n",
    "        a integer to indicate number of output units (default 1)\n",
    "    learning_rate : float\n",
    "        a real number between 0 and 1 specifyng the learning rate (default 0.05) \n",
    "    momentum : float\n",
    "        a real number between 0 and 1 specifyng the momentum (default 0.9)\n",
    "    tol : float\n",
    "        a real number specifying a threshold for improvement in error under which early stopping occurs (default 1e-4)\n",
    "    n_epoch_no_change : int\n",
    "        an integer specifying the number of epochs in a row needed where improvement in error is below tol for early stopping to occure (default 10)\n",
    "    batch_size : int\n",
    "        the batch size for stochastic gradient descent (default 1)\n",
    "    epochs : int\n",
    "        the number of times each data sample is used for training (default 5)\n",
    "    shuffle : bool\n",
    "        whether to shuffle samples before training (default True)\n",
    "    quiet : bool\n",
    "        whether to output updates during training (default False)\n",
    "    \n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    fit(X_tr, y_tr = None, threshold = .5, nesterov = True, xval = None, yval = None)\n",
    "        Fits the ANN class object using training data\n",
    "    predict(X, y = None)\n",
    "        Predicts samples using ANN class object, cannot be evoked before fit method\n",
    "    score(y_true, y_pred)\n",
    "        Computes negative of half the sum of squared differences between true and predicted labels\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "               n_input, \n",
    "               n_hidden = (5,),\n",
    "               seed = round(np.random.uniform()*1000), \n",
    "               act_h = 'relu',\n",
    "               n_output = 1, \n",
    "               learning_rate = 0.05, \n",
    "               momentum = 0.9,\n",
    "               tol = 1e-4,\n",
    "               n_epoch_no_change = 10,\n",
    "               batch_size = 1,\n",
    "               epochs = 5,\n",
    "               shuffle = True,\n",
    "               quiet = False):\n",
    "        \"\"\"Initializes an ANN class object\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            n_input : int\n",
    "                a integer to indicate number of input units (features)\n",
    "            n_hidden : tuple, optional\n",
    "                a tuple containing a maximum of 2 integers indicatng size of (number of units in) each hidden layer (default (5,))\n",
    "            seed : int, optional\n",
    "                the random state to use for initializing weights and data shuffle (default random)\n",
    "            act_h : str, optional\n",
    "                the activation function to use, on of 'sigmoid' or 'relu' (default 'relu')\n",
    "            n_output : int, optional\n",
    "                a integer to indicate number of output units (default 1)\n",
    "            learning_rate : float, optional\n",
    "                a real number between 0 and 1 specifyng the learning rate (default 0.05) \n",
    "            momentum : float, optional\n",
    "                a real number between 0 and 1 specifyng the momentum (default 0.9)\n",
    "            tol : float, optional\n",
    "                a real number specifying a threshold for improvement in error under which early stopping occurs (default 1e-4)\n",
    "            n_epoch_no_change : int, optional\n",
    "                an integer specifying the number of epochs in a row needed where improvement in error is below tol for early stopping to occure (default 10)\n",
    "            batch_size : int, optional\n",
    "                the batch size for stochastic gradient descent (default 1)\n",
    "            epochs : int, optional\n",
    "                the number of times each data sample is used for training (default 5)\n",
    "            shuffle : bool, optional\n",
    "                whether to shuffle samples before training (default True)\n",
    "            quiet : bool, optional\n",
    "                whether to output updates during training (default False)\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            ANN class object\n",
    "                an ANN class object of specified parameters (all are saved as object attributes)\n",
    "                model contains momentum with nesterov option and minibatch stochastic gradient descent\n",
    "                model does not contain bias or L2 regularization\n",
    "\n",
    "                Additional attributes:\n",
    "                n_hlayer : int\n",
    "                    the number of hidden layers based on length of n_hidden\n",
    "            \"\"\"\n",
    "\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        if(len(n_hidden) == 1):\n",
    "            self.n_hlayer = 1\n",
    "        else:\n",
    "            self.n_hlayer = 2\n",
    "\n",
    "        self.n_output = n_output\n",
    "        self.seed = seed\n",
    "        self.act_h = act_h\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.tol = tol\n",
    "        self.n_epoch_no_change = n_epoch_no_change\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.shuffle = shuffle\n",
    "        self.quiet = quiet\n",
    "\n",
    "    def predict(self, X, y = None):\n",
    "        \"\"\"Predicts given samples using ANN class object\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array\n",
    "            The samples to predict in a 2D array of size n_samples x n_inputs\n",
    "        y : numpy.array, optional\n",
    "            The true labels in a 2D array of size n_samples x n_outputs (default None)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.array\n",
    "            Predicted labels in a 2D array of size n_samples x n_outputs\n",
    "        \"\"\"\n",
    "\n",
    "        if(X.shape[1] != self.n_input):\n",
    "              sys.exit(\"Input data is of wrong dimensions.\")\n",
    "\n",
    "        else:\n",
    "            if(self.act_h == 'relu'):\n",
    "\n",
    "                    if(self.n_hlayer == 1):\n",
    "                          return(sigmoid(np.matmul(relu(np.matmul(X, self.hlayer_w)), self.olayer_w)))\n",
    "                    else:\n",
    "                          return(sigmoid(np.matmul(relu(np.matmul(relu(np.matmul(X, self.hlayer_w)), self.hlayer_w2)), self.olayer_w)))\n",
    "\n",
    "            else:\n",
    "\n",
    "                    if(self.n_hlayer == 1):\n",
    "                          return(sigmoid(np.matmul(sigmoid(np.matmul(X, self.hlayer_w)), self.olayer_w)))\n",
    "                    else:\n",
    "                          return(sigmoid(np.matmul(sigmoid(np.matmul(sigmoid(np.matmul(X, self.hlayer_w)), self.hlayer_w2)), self.olayer_w)))\n",
    "\n",
    "    def eval(self, X):\n",
    "        \"\"\"Evaluates given samples using ANN class object\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array\n",
    "            The samples to evaluate in a 2D array of size n_samples x n_inputs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.array\n",
    "            Output of first hidden layer in a 2D array of size n_hidden[0] x n_samples\n",
    "        numpy.array\n",
    "            Output of second hidden layer in a 2D array of size n_hidden[1] x n_samples, 1 if no second layer exists\n",
    "        numpy.array\n",
    "            Predicted probabilities in a 2D array of size n_samples x n_outputs\n",
    "        \"\"\"\n",
    "\n",
    "        if(X.shape[1] != self.n_input):\n",
    "            sys.exit(\"Input data is of wrong dimensions.\")\n",
    "\n",
    "        else:\n",
    "\n",
    "            if(self.act_h == 'relu'):\n",
    "\n",
    "                    if(self.n_hlayer == 1):\n",
    "                        h_out = np.matmul(X, self.hlayer_w).reshape((self.n_hidden[0], X.shape[0]))\n",
    "                        h_out2 = 1\n",
    "                        y_prob = sigmoid(np.matmul(relu(h_out.T), self.olayer_w))\n",
    "\n",
    "                    else:\n",
    "                        h_out = np.matmul(X, self.hlayer_w).reshape((self.n_hidden[0], X.shape[0]))\n",
    "                        h_out2 = np.matmul(relu(h_out.T), self.hlayer_w2).reshape((self.n_hidden[1], X.shape[0]))\n",
    "                        y_prob =  sigmoid(np.matmul(relu(h_out2.T), self.olayer_w))\n",
    "            else:\n",
    "\n",
    "                    if(self.n_hlayer == 1):\n",
    "                        h_out = sigmoid(np.matmul(X, self.hlayer_w)).reshape((self.n_hidden[0], X.shape[0]))\n",
    "                        h_out2 = 1\n",
    "                        y_prob = sigmoid(np.matmul(h_out.T, self.olayer_w))\n",
    "\n",
    "                    else:\n",
    "                        h_out = sigmoid(np.matmul(X, self.hlayer_w)).reshape((self.n_hidden[0], X.shape[0]))\n",
    "                        h_out2 = sigmoid(np.matmul(h_out.T, self.hlayer_w2)).reshape((self.n_hidden[1], X.shape[0]))\n",
    "                        y_prob = sigmoid(np.matmul(h_out2.T, self.olayer_w))\n",
    "\n",
    "        return(h_out, h_out2, y_prob)\n",
    "\n",
    "    def score(self, y_true, y_pred):\n",
    "        \"\"\"Computes negative of half the sum of squared differences between true and predicted labels\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : numpy.array\n",
    "            The true labels in a 2D array of size n_samples x 1\n",
    "        y_pred : numpy.array\n",
    "            The predicted labels in a 2D array of size n_samples x 1  \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            negative of half the sum of squared differences\n",
    "        \"\"\"\n",
    "        return(-(0.5*np.sum((y_true - y_pred)**2)))\n",
    "  \n",
    "    def fit(self, X_tr, y_tr = None, threshold = .5, nesterov = True, xval = None, yval = None):\n",
    "        \"\"\"\n",
    "        Trains an ANN class object model using training data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_tr : numpy.array\n",
    "            The training samples in a 2D array of size n_samples x n_inputs\n",
    "        y_tr : numpy.array\n",
    "            The true training labels in a 2D array of size n_samples x 1 (default None)\n",
    "        threshold : float, optional\n",
    "            the threshold used for binary output, only used to compute accuracy (default .5)\n",
    "        nesterov : bool, optional\n",
    "            whether to use Nesterov's momentum or not (default True)\n",
    "        xval : numpy.array, optional\n",
    "            The validation samples in a 2D array of size n_samples x n_inputs, used to compute and save error at each epoch (default None)\n",
    "        yval : numpy.array, optional\n",
    "            The validation true labels in a 2D array of size n_samples x 1, used to compute and save error at each epoch (default None)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "            Additional attributes:\n",
    "            hlayer_w : numpy.array\n",
    "                weights for the first hidden layer in a 2D array of size n_input x n_hidden[0]\n",
    "            hlayer_w2 : numpy.array or int\n",
    "                weights for the second hidden layer in a 2D array of size n_hidden[0] x n_hidden[1]\n",
    "            olayer_w : numpy.array\n",
    "                weights for the output layer in a 2D array of size n_hidden[0 or 1] x n_output\n",
    "            pred : numpy.array\n",
    "                final predicted probabilities in a 2D array of size n_samples x n_output\n",
    "            min_err : float\n",
    "                minimum normalized error\n",
    "            best_epoch: int\n",
    "                epoch at which minimum normalized error occured\n",
    "            stop_err : float\n",
    "                error at stopping epoch\n",
    "            stop_epoch: int\n",
    "                epoch at which early stopping occured\n",
    "            errs: list\n",
    "                training errors at each epoch\n",
    "            val_errs: list, only if xval and yval not None\n",
    "                validation errors at each epoch\n",
    "        \"\"\"\n",
    "        def create_layer(i, j):\n",
    "            \"\"\"Creates a layer of random weights between -0.05 and 0.05 with specified dimensions i x j\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                i : int\n",
    "                    Number of rows\n",
    "                j : int\n",
    "                    Number of columns\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                numpy.array\n",
    "                    2D array of random weights of size i x j \n",
    "            \"\"\"\n",
    "            return((np.random.rand(i, j) - 0.5)/10)\n",
    "\n",
    "        def get_error(y_hat, y):\n",
    "            \"\"\"Computes half of sum of squared differences between true and predicted labels\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                y_hat : numpy.array\n",
    "                    The predicted labels in a 2D array of size n_samples x 1\n",
    "                y : numpy.array\n",
    "                    The true labels in a 2D array of size n_samples x 1\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                float\n",
    "                    half of sum of squared differences\n",
    "            \"\"\"\n",
    "            return(0.5*np.sum((y - y_hat)**2))\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        if(self.n_hlayer == 1):\n",
    "            self.hlayer_w = create_layer(self.n_input, self.n_hidden[0])\n",
    "            self.olayer_w = create_layer(self.n_hidden[0], self.n_output)\n",
    "\n",
    "        else:\n",
    "            self.hlayer_w = create_layer(self.n_input, self.n_hidden[0])\n",
    "            self.hlayer_w2 = create_layer(self.n_hidden[0], self.n_hidden[1])\n",
    "            self.olayer_w = create_layer(self.n_hidden[1], self.n_output)\n",
    "\n",
    "        y_hats = self.predict(X_tr)\n",
    "        err = get_error(y_hats, y_tr)\n",
    "        val = False\n",
    "\n",
    "        if((xval is not None) and (yval is not None)):\n",
    "            val = True\n",
    "            y_hats_val = self.predict(xval)\n",
    "            err_val = get_error(y_hats_val, yval)\n",
    "            self.errs_val = [err_val/y_hats_val.shape[0]]\n",
    "\n",
    "        if(not self.quiet):\n",
    "            print(\"========Training Error\", str(err))\n",
    "            print(\"========Training Accuracy\", str(np.mean((y_hats > threshold) == y_tr)))\n",
    "            if(val):\n",
    "                print(\"========Validation Error\", str(err_val))\n",
    "                print(\"========Validation Accuracy\", str(np.mean((y_hats_val > threshold) == yval)))\n",
    "\n",
    "        self.min_err = err/y_hats.shape[0]\n",
    "        self.best_epoch = 0\n",
    "        self.errs = [err/y_hats.shape[0]]\n",
    "\n",
    "        prev_err = err\n",
    "        no_change_count = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "          df = np.concatenate((X_tr, y_tr), axis = 1)\n",
    "\n",
    "          if(self.shuffle):\n",
    "          #Shuffle samples at each epoch\n",
    "            np.random.seed(self.seed + epoch)\n",
    "            np.random.shuffle(df)\n",
    "\n",
    "          if(not self.quiet):\n",
    "            print(\"====================================\")\n",
    "            print(\"Epoch\", str(epoch + 1))\n",
    "\n",
    "          prev_deltahw = 0\n",
    "          prev_deltahw2 = 0\n",
    "          prev_deltaow = 0\n",
    "\n",
    "          if(self.batch_size > 1):\n",
    "\n",
    "            for batch in np.array_split(df, df.shape[0]//self.batch_size):\n",
    "              X_train = batch[:,0:self.n_input]\n",
    "              y_train = batch[:,self.n_input].reshape((batch.shape[0], 1))\n",
    "\n",
    "              if(nesterov):\n",
    "                self.olayer_w += self.momentum*prev_deltaow\n",
    "                self.hlayer_w += self.momentum*prev_deltahw\n",
    "\n",
    "                if(self.n_hlayer > 1):\n",
    "                  self.hlayer_w2 += self.momentum*prev_deltahw2\n",
    "\n",
    "              h_out, h_out2, y_hat = self.eval(X_train)\n",
    "              err_o = y_hat*(1 - y_hat)*(y_train - y_hat)\n",
    "\n",
    "              if(self.act_h == 'relu'):\n",
    "\n",
    "                if(self.n_hlayer == 1):\n",
    "                  err_h = (h_out > 0).astype(int) * self.olayer_w * err_o.T\n",
    "                  deltaow = self.learning_rate*(relu(h_out)@err_o)\n",
    "                  self.olayer_w += deltaow + self.momentum*prev_deltaow\n",
    "\n",
    "                else:\n",
    "                  err_h2 = (h_out2 > 0).astype(int) * self.olayer_w * err_o.T\n",
    "                  err_h = (h_out > 0).astype(int) * (self.hlayer_w2 @ err_h2)\n",
    "                  deltaow = self.learning_rate*(relu(h_out2)@err_o)\n",
    "                  self.olayer_w += deltaow + self.momentum*prev_deltaow\n",
    "                  deltahw2 = (self.learning_rate*(relu(h_out)@err_h2.T))\n",
    "                  self.hlayer_w2 += deltahw2 + self.momentum*prev_deltahw2\n",
    "\n",
    "                  if(nesterov):\n",
    "                    self.hlayer_w2 -= self.momentum*prev_deltahw2\n",
    "\n",
    "                  prev_deltahw2 = deltahw2\n",
    "\n",
    "              else:\n",
    "\n",
    "                if(self.n_hlayer == 1):\n",
    "                  err_h = h_out * (1 - h_out) * self.olayer_w * err_o.T\n",
    "                  deltaow = self.learning_rate*(h_out@err_o)\n",
    "                  self.olayer_w += deltaow + self.momentum*prev_deltaow\n",
    "\n",
    "                else:\n",
    "                  err_h2 = h_out2 * (1 - h_out2) * self.olayer_w * err_o.T\n",
    "                  err_h = h_out * (1 - h_out) * (self.hlayer_w2 @ err_h2)\n",
    "                  deltaow = self.learning_rate*(h_out2@err_o)\n",
    "                  self.olayer_w += deltaow + self.momentum*prev_deltaow\n",
    "                  deltahw2 = (self.learning_rate*(h_out@err_h2.T))\n",
    "                  self.hlayer_w2 += deltahw2 + self.momentum*prev_deltahw2\n",
    "\n",
    "                  if(nesterov):\n",
    "                    self.hlayer_w2 -= self.momentum*prev_deltahw2\n",
    "\n",
    "                  prev_deltahw2 = deltahw2\n",
    "\n",
    "              deltahw = (self.learning_rate*err_h@X_train).T\n",
    "              self.hlayer_w += deltahw + self.momentum*prev_deltahw\n",
    "\n",
    "              if(nesterov):\n",
    "                self.hlayer_w -= self.momentum*prev_deltahw\n",
    "                self.olayer_w -= self.momentum*prev_deltaow\n",
    "\n",
    "              prev_deltaow = deltaow\n",
    "              prev_deltahw = deltahw\n",
    "\n",
    "          else:\n",
    "            #slower implementation than batch_size > 1\n",
    "            X_train = df[:,0:self.n_input]\n",
    "            y_train = df[:,self.n_input].reshape((df.shape[0], 1))\n",
    "\n",
    "            for n in range(X_train.shape[0]):\n",
    "              instance = X_train[n,:].reshape((1, self.n_input))\n",
    "\n",
    "              if(nesterov):\n",
    "                self.olayer_w += self.momentum*prev_deltaow\n",
    "                self.hlayer_w += self.momentum*prev_deltahw\n",
    "\n",
    "                if(self.n_hlayer > 1):\n",
    "                  self.hlayer_w2 += self.momentum*prev_deltahw2\n",
    "\n",
    "              h_out, h_out2, y_hat = self.eval(instance)\n",
    "              err_o = y_hat*(1 - y_hat)*(y_train[n,:] - y_hat)\n",
    "\n",
    "              if(self.act_h == 'relu'):\n",
    "\n",
    "                if(self.n_hlayer == 1):\n",
    "                  err_h = (h_out > 0).astype(int) * self.olayer_w * err_o\n",
    "                  deltaow = self.learning_rate*err_o*relu(h_out)\n",
    "                  self.olayer_w += deltaow + self.momentum*prev_deltaow\n",
    "\n",
    "                else:\n",
    "                  err_h2 = (h_out2 > 0).astype(int) * self.olayer_w * err_o\n",
    "                  err_h = (h_out > 0).astype(int) * (self.hlayer_w2 @ err_h2)\n",
    "                  deltaow = self.learning_rate*err_o*relu(h_out2)\n",
    "                  deltahw2 = (self.learning_rate*err_h2*relu(h_out).T).T\n",
    "                  self.olayer_w += deltaow + self.momentum*prev_deltaow\n",
    "                  self.hlayer_w2 += deltahw2 + self.momentum*prev_deltahw2\n",
    "\n",
    "                  if(nesterov):\n",
    "                    self.hlayer_w2 -= self.momentum*prev_deltahw2\n",
    "\n",
    "                  prev_deltahw2 = deltahw2\n",
    "\n",
    "              else:\n",
    "\n",
    "                if(self.n_hlayer == 1):\n",
    "                  err_h = h_out * (1 - h_out) * self.olayer_w * err_o\n",
    "                  deltaow = self.learning_rate*err_o*h_out\n",
    "                  self.olayer_w += deltaow + self.momentum*prev_deltaow\n",
    "\n",
    "                else:\n",
    "                  err_h2 = h_out2 * (1 - h_out2) * self.olayer_w * err_o\n",
    "                  err_h = h_out * (1 - h_out) * (self.hlayer_w2 @ err_h2)\n",
    "                  deltaow = self.learning_rate*err_o*h_out2\n",
    "                  self.olayer_w += deltaow + self.momentum*prev_deltaow\n",
    "                  deltahw2 = (self.learning_rate*err_h2*h_out.T).T\n",
    "                  self.hlayer_w2 += deltahw2 + self.momentum*prev_deltahw2\n",
    "\n",
    "                  if(nesterov):\n",
    "                    self.hlayer_w2 -= self.momentum*prev_deltahw2\n",
    "\n",
    "                  prev_deltahw2 = deltahw2\n",
    "\n",
    "              deltahw = (self.learning_rate*err_h*instance).T\n",
    "              self.hlayer_w += deltahw + self.momentum*prev_deltahw\n",
    "\n",
    "              if(nesterov):\n",
    "                self.hlayer_w -= self.momentum*prev_deltahw\n",
    "                self.olayer_w -= self.momentum*prev_deltaow\n",
    "\n",
    "              prev_deltaow = deltaow\n",
    "              prev_deltahw = deltahw\n",
    "\n",
    "          y_hats = self.predict(X_tr)\n",
    "          err = get_error(y_hats, y_tr)\n",
    "          self.errs.append(err/y_hats.shape[0])\n",
    "\n",
    "          if(val):\n",
    "            y_hats_val = self.predict(xval)\n",
    "            err_val = get_error(y_hats_val, yval)\n",
    "            self.errs_val.append(err_val/y_hats_val.shape[0])\n",
    "\n",
    "          if(err/y_hats.shape[0] < self.min_err):\n",
    "            self.min_err = err/y_hats.shape[0]\n",
    "            self.best_epoch = epoch\n",
    "\n",
    "          if(not self.quiet):\n",
    "            print(\"========Error\", str(err))\n",
    "            print(\"========Accuracy\", str(np.mean((y_hats > threshold) == y_tr)))\n",
    "            if(val):\n",
    "              print(\"========Validation Error\", str(err_val))\n",
    "              print(\"========Validation Accuracy\", str(np.mean((y_hats_val > threshold) == yval)))\n",
    "\n",
    "          if(prev_err - err < self.tol):\n",
    "          #record number of consecutive epochs of subthreshold improvement in error\n",
    "            no_change_count += 1\n",
    "          else:\n",
    "            no_change_count = 0\n",
    "\n",
    "          self.stop_epoch = epoch\n",
    "          self.stop_err = err/y_hats.shape[0]\n",
    "\n",
    "          if(no_change_count == self.n_epoch_no_change):\n",
    "          #Early stopping when consecutive epochs of subthreshold improvement in error reaches n_epoch_no_change\n",
    "            if(not self.quiet):\n",
    "              print(\"========Early stopping!========\")\n",
    "\n",
    "            break\n",
    "\n",
    "          prev_err = err\n",
    "\n",
    "        self.pred = y_hats\n",
    "\n",
    "        if(not self.quiet):\n",
    "          print(\"============DONE====================\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIu2Ho0y67u5"
   },
   "source": [
    "My ANN on Disjunction of 5 Booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJdnNKz29XZh",
    "outputId": "291a3803-fa6a-47be-be66-1ccb0e203045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 1]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 1 1]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 1]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 1]\n",
      " [0 1 1 1 0]\n",
      " [0 1 1 1 1]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 1]\n",
      " [1 0 0 1 0]\n",
      " [1 0 0 1 1]\n",
      " [1 0 1 0 0]\n",
      " [1 0 1 0 1]\n",
      " [1 0 1 1 0]\n",
      " [1 0 1 1 1]\n",
      " [1 1 0 0 0]\n",
      " [1 1 0 0 1]\n",
      " [1 1 0 1 0]\n",
      " [1 1 0 1 1]\n",
      " [1 1 1 0 0]\n",
      " [1 1 1 0 1]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 1]]\n",
      "(32, 5) (32, 1)\n",
      "========Training Error 4.000265088614569\n",
      "========Training Accuracy 0.03125\n",
      "====================================\n",
      "Epoch 1\n",
      "========Error 3.9998076156619065\n",
      "========Accuracy 0.40625\n",
      "====================================\n",
      "Epoch 2\n",
      "========Error 3.9970448465694424\n",
      "========Accuracy 0.75\n",
      "====================================\n",
      "Epoch 3\n",
      "========Error 3.8798738426356887\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 4\n",
      "========Error 1.598989560470874\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 5\n",
      "========Error 0.5468080963554875\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 6\n",
      "========Error 0.35311903337239486\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 7\n",
      "========Error 0.2764755191406224\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 8\n",
      "========Error 0.2375355774402333\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 9\n",
      "========Error 0.2138012062740915\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 10\n",
      "========Error 0.19870740896202224\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 11\n",
      "========Error 0.1876391319780847\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 12\n",
      "========Error 0.17870557800391967\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 13\n",
      "========Error 0.1717612336697311\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 14\n",
      "========Error 0.16623223913902713\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 15\n",
      "========Error 0.16173628330678527\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 16\n",
      "========Error 0.15802848875143133\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 17\n",
      "========Error 0.15518434812454618\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 18\n",
      "========Error 0.15275705424448183\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 19\n",
      "========Error 0.15044359449159203\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 20\n",
      "========Error 0.14844527494681214\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 21\n",
      "========Error 0.14670597369532715\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 22\n",
      "========Error 0.14518068979877832\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 23\n",
      "========Error 0.1438328312816043\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 24\n",
      "========Error 0.1426340014051499\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 25\n",
      "========Error 0.14156327638973795\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 26\n",
      "========Error 0.14060140425585171\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 27\n",
      "========Error 0.13973402572996674\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 28\n",
      "========Error 0.13901923756742593\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 29\n",
      "========Error 0.13829830496087475\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 30\n",
      "========Error 0.1376392661823133\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 31\n",
      "========Error 0.137035467598026\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 32\n",
      "========Error 0.13648168248887463\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 33\n",
      "========Error 0.1359711380937226\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 34\n",
      "========Error 0.13549937695111378\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 35\n",
      "========Error 0.13510411572715303\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 36\n",
      "========Error 0.13469498343913527\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 37\n",
      "========Error 0.1343142517247401\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 38\n",
      "========Error 0.1339939452068176\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 39\n",
      "========Error 0.1336599844292146\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 40\n",
      "========Error 0.13334749228897166\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 41\n",
      "========Error 0.13308090076951243\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 42\n",
      "========Error 0.13280437474729104\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 43\n",
      "========Error 0.1325440525554345\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 44\n",
      "========Error 0.13229901030790076\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 45\n",
      "========Error 0.13208882841489453\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 46\n",
      "========Error 0.13186910663316767\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 47\n",
      "========Error 0.1316613653253241\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 48\n",
      "========Error 0.13146450062231058\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 49\n",
      "========Error 0.1312777929265089\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 50\n",
      "========Error 0.13110052904299604\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 51\n",
      "========Error 0.1309321378622588\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 52\n",
      "========Error 0.13077181345680508\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 53\n",
      "========Error 0.13061917923182945\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 54\n",
      "========Error 0.13047357135510637\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 55\n",
      "========Error 0.13033467852626898\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 56\n",
      "========Error 0.13020193274158912\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 57\n",
      "========Error 0.1300750024099839\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 58\n",
      "========Error 0.12995359433879194\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 59\n",
      "========Error 0.1298372595189534\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 60\n",
      "========Error 0.12972575957864338\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 61\n",
      "========Error 0.12961885637793466\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 62\n",
      "========Error 0.12951619203974432\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 63\n",
      "========Error 0.129417566321385\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 64\n",
      "========Error 0.1293227625764452\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 65\n",
      "========Error 0.12923157358060516\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 66\n",
      "========Error 0.12914382288763987\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 67\n",
      "========Error 0.12905928094854258\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 68\n",
      "========Error 0.12897781694629754\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 69\n",
      "========Error 0.1288992839740122\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 70\n",
      "========Error 0.12883016979231626\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 71\n",
      "========Error 0.1287567690263149\n",
      "========Accuracy 1.0\n",
      "====================================\n",
      "Epoch 72\n",
      "========Error 0.1286925068146207\n",
      "========Accuracy 1.0\n",
      "========Early stopping!========\n",
      "============DONE====================\n",
      "Predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.96150057],\n",
       "       [0.96229811],\n",
       "       [0.99843369],\n",
       "       [0.96139514],\n",
       "       [0.99839473],\n",
       "       [0.99842924],\n",
       "       [0.99993701],\n",
       "       [0.96086985],\n",
       "       [0.99837204],\n",
       "       [0.99840703],\n",
       "       [0.99993612],\n",
       "       [0.99836741],\n",
       "       [0.99993453],\n",
       "       [0.99993594],\n",
       "       [0.99999743],\n",
       "       [0.96212416],\n",
       "       [0.99842619],\n",
       "       [0.99846002],\n",
       "       [0.99993825],\n",
       "       [0.99842172],\n",
       "       [0.99993671],\n",
       "       [0.99993807],\n",
       "       [0.99999752],\n",
       "       [0.9983994 ],\n",
       "       [0.99993581],\n",
       "       [0.99993719],\n",
       "       [0.99999749],\n",
       "       [0.99993563],\n",
       "       [0.99999742],\n",
       "       [0.99999748],\n",
       "       [0.9999999 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate combinations of possible inputs\n",
    "disj5 = np.array([list(numbers) for numbers in itertools.product([0, 1], repeat=5)])\n",
    "#Generate result of disjunctions of inputs\n",
    "disj5_y = np.array([int(np.any(i)) for i in disj5]).reshape((disj5.shape[0], 1))\n",
    "print(\"Instances\")\n",
    "print(disj5)\n",
    "print(disj5.shape, disj5_y.shape)\n",
    "\n",
    "#Fit my ANN with 1 hidden unit for 100 epochs\n",
    "ann = ANN(n_input = 5, \n",
    "          n_hidden = (1,),\n",
    "          seed = 123, \n",
    "          act_h = 'relu', \n",
    "          learning_rate = 0.25,\n",
    "          batch_size = 1,\n",
    "          epochs = 100)\n",
    "\n",
    "ann.fit(disj5, disj5_y)\n",
    "print(\"Predictions\")\n",
    "ann.pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTdSJtJzX9Ir"
   },
   "source": [
    "Importing Steinmetz Data and K-Fold splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8xH897ehHCg",
    "outputId": "5a6c208d-723f-43a4-e78f-272de413759e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7012, 20) (7012, 1)\n"
     ]
    }
   ],
   "source": [
    "df_tr = np.array(pd.read_csv(\"data_transformed_train.csv\", index_col = 0))\n",
    "splits = pd.read_csv('splits10by10.csv', index_col = 0).reset_index(drop = True) - 1\n",
    "\n",
    "X_train = df_tr[:,0:20]\n",
    "y_train = df_tr[:,20].reshape((X_train.shape[0],1))\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfcVn5UPWhPK",
    "outputId": "a44462a5-9ad6-4bfa-d73c-97071fbbaefc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 20) (1038, 1)\n"
     ]
    }
   ],
   "source": [
    "df_te = np.array(pd.read_csv(\"data_transformed_test.csv\", index_col = 0))\n",
    "\n",
    "X_test = df_te[:,0:20]\n",
    "y_test = df_te[:,20].reshape((X_test.shape[0],1))\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWP4hq0x61QW"
   },
   "source": [
    "Tuning My ANN, sklearn MLPC, and SVM on Steinmetz Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "auENwlb8V73e"
   },
   "outputs": [],
   "source": [
    "def inv_squared_diff(y_true, y_pred):\n",
    "    \"\"\"Computes the sum of squared differences for true and predicted labels.\n",
    "       The score is negative to be maximized instead of minimized.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : numpy.array\n",
    "        The true labels\n",
    "    y_pred : numpy.array\n",
    "        The predicted label\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The negative of the sum of squared differences\n",
    "    \"\"\"\n",
    "    return(-(0.5*np.sum((y_true - y_pred)**2)))\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    \"\"\"Saved python object as pickle file to current directory\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : any\n",
    "        The python object to save\n",
    "    filename : str\n",
    "        The file name to use for .pkl file (format: '_.pkl')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def read_object(name):\n",
    "    \"\"\"Read pickle file as python object from current directory\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        The .pkl file name excluding '.pkl' extension (format: name.pkl)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    any\n",
    "        The python object contained in the pickle file\n",
    "    \"\"\"\n",
    "    fName = str(name + '.pkl')\n",
    "    with open(fName, 'rb') as f:  # with statement avoids file leak\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uich-nyR6y2V",
    "outputId": "736eaa62-3f16-42f6-e948-20a7664922c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 1\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:56: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:56: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:56: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 2\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:56: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:56: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:56: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 3\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/var/folders/9n/c4d07xnn5bggw283th1gs7h00000gn/T/ipykernel_847/1034841128.py:56: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "====Done====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Define parameters/distributions to tune over with RandomizedSearchCV\n",
    "n_units = [1, 3, 6, 10, 15, 20] \n",
    "params = dict(my_ann__learning_rate = uniform(0, 0.2), \n",
    "              my_ann__momentum = uniform(),\n",
    "              my_ann__act_h = ['relu', 'sigmoid'],\n",
    "              my_ann__n_hidden = [tuple(i) for i in itertools.product(n_units, repeat=2)] + [tuple([i]) for i in n_units], #Create combinations of n_units for single and double layer ANNs\n",
    "              my_ann__batch_size = randint(1, math.ceil(math.floor(X_train.shape[0]*0.9)/2)))\n",
    "params_sk = dict(mlpc__learning_rate_init = uniform(0, 0.2),\n",
    "              mlpc__momentum = uniform(),\n",
    "              mlpc__hidden_layer_sizes = [tuple(i) for i in itertools.product(n_units, repeat=2)] + [tuple([i]) for i in n_units], #Create combinations of n_units for single and double layer ANNs\n",
    "              mlpc__activation = ['relu', 'logistic'],\n",
    "              mlpc__batch_size = randint(1, math.ceil(math.floor(X_train.shape[0]*0.9)/2))) #From 1 to around half the total training sample size\n",
    "params_svm = [dict(svc__kernel = ['poly'],\n",
    "              svc__degree = randint(1,4),\n",
    "              svc__C = expon(0,7),\n",
    "              svc__gamma = uniform()), \n",
    "              dict(svc__kernel = ['rbf'],\n",
    "               svc__C = expon(0,7),\n",
    "              svc__gamma = uniform()),\n",
    "              dict(svc__kernel = ['sigmoid'],\n",
    "              svc__C = expon(0,7),\n",
    "              svc__gamma = uniform())]\n",
    "scorer = make_scorer(inv_squared_diff, needs_proba = True) #Make common scorer to be maximized by search\n",
    "\n",
    "searches = list()\n",
    "searches_sk = list()\n",
    "#searches_svm = list()\n",
    "\n",
    "n_iter = 3\n",
    "max_epochs = 100\n",
    "for i in range(n_iter):\n",
    "    #Tune each model n_iter times using same folds as C5.0 CV.\n",
    "    #Each fold is scaled before use\n",
    "    #Initialize models differently each time but keep randomly sampled params constant\n",
    "  print(\"======================\")\n",
    "  print(\"Iteration\", str(i + 1))\n",
    "  group_kfold = GroupKFold(n_splits=10)\n",
    "  steps = [('scaler', StandardScaler(with_mean = False)), \n",
    "           ('my_ann', ANN(n_input = 20, epochs = max_epochs, seed = 123 + i, quiet = True))]\n",
    "  steps_sk = [('scaler', StandardScaler(with_mean = False)), \n",
    "           ('mlpc', MLPClassifier(solver = 'sgd', random_state = 123 + i, max_iter = max_epochs))]\n",
    "  steps_svm = [('scaler', StandardScaler(with_mean = False)), \n",
    "           ('svc', svm.SVC(probability = True, random_state = 123 + i))]\n",
    "  pipeline = Pipeline(steps)\n",
    "  pipeline_sk = Pipeline(steps_sk)\n",
    "  pipeline_svm = Pipeline(steps_svm)\n",
    "\n",
    "  myAnnCV = RandomizedSearchCV(pipeline, params, random_state = 123, return_train_score = True, cv = group_kfold, n_jobs = 2, verbose = 1)\n",
    "  skAnnCV = RandomizedSearchCV(pipeline_sk, params_sk, random_state = 123, return_train_score = True, cv = group_kfold, n_jobs = 2, scoring = scorer, verbose = 1)\n",
    "  #SVM was tuned separately for time using same protocol with some mistakes (could not rerun for time)\n",
    "  #svmCV = RandomizedSearchCV(pipeline_svm, params_svm, random_state = 123, return_train_score = True, cv = group_kfold, n_jobs = 2, scoring = scorer, verbose = 1)\n",
    "  \n",
    "  searches.append(myAnnCV.fit(X_train, y_train, groups = splits.iloc[:,i].tolist()))\n",
    "  searches_sk.append(skAnnCV.fit(X_train, np.ravel(y_train), groups = splits.iloc[:,i].tolist()))\n",
    "  #searches_svm.append(svmCV.fit(X_train, np.ravel(y_train), groups = splits.iloc[:,i].tolist()))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(\"====Done====\")\n",
    "\n",
    "save_object(searches, 'searches.pkl')\n",
    "save_object(searches_sk, 'searches_sk.pkl')\n",
    "#save_object(searches_svm, 'searches_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searches_svm = read_object('searches_svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPpHgR02dV78",
    "outputId": "4804ca97-1566-4fb0-f607-76f57e3b8038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Ann\n",
      "{'my_ann__act_h': 'relu', 'my_ann__batch_size': 1347, 'my_ann__learning_rate': 0.04537029071284063, 'my_ann__momentum': 0.5513147690828912, 'my_ann__n_hidden': (10, 3)}\n",
      "{'my_ann__act_h': 'relu', 'my_ann__batch_size': 1347, 'my_ann__learning_rate': 0.04537029071284063, 'my_ann__momentum': 0.5513147690828912, 'my_ann__n_hidden': (10, 3)}\n",
      "{'my_ann__act_h': 'relu', 'my_ann__batch_size': 1347, 'my_ann__learning_rate': 0.04537029071284063, 'my_ann__momentum': 0.5513147690828912, 'my_ann__n_hidden': (10, 3)}\n"
     ]
    }
   ],
   "source": [
    "print('My Ann')\n",
    "print(searches[0].best_params_)\n",
    "print(searches[1].best_params_)\n",
    "print(searches[2].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHaygGki6roP",
    "outputId": "f0f1a90f-5e66-4fd0-a35a-dc463c9e556e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPC\n",
      "{'mlpc__activation': 'logistic', 'mlpc__batch_size': 74, 'mlpc__hidden_layer_sizes': (20, 6), 'mlpc__learning_rate_init': 0.06863560323017388, 'mlpc__momentum': 0.7290497073840416}\n",
      "{'mlpc__activation': 'logistic', 'mlpc__batch_size': 74, 'mlpc__hidden_layer_sizes': (20, 6), 'mlpc__learning_rate_init': 0.06863560323017388, 'mlpc__momentum': 0.7290497073840416}\n",
      "{'mlpc__activation': 'logistic', 'mlpc__batch_size': 74, 'mlpc__hidden_layer_sizes': (20, 6), 'mlpc__learning_rate_init': 0.06863560323017388, 'mlpc__momentum': 0.7290497073840416}\n"
     ]
    }
   ],
   "source": [
    "print('MLPC')\n",
    "print(searches_sk[0].best_params_)\n",
    "print(searches_sk[1].best_params_)\n",
    "print(searches_sk[2].best_params_)\n",
    "#-pd.concat([pd.DataFrame(searches_sk[i].cv_results_).iloc[searches_sk[i].best_index_,:] for i in range(3)], axis = 1).loc['mean_test_score',:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YTzKC4Kzo4D_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "{'svc__C': 27.656874481703028, 'svc__gamma': 0.6848297385848633, 'svc__kernel': 'rbf'}\n",
      "{'svc__C': 27.656874481703028, 'svc__gamma': 0.6848297385848633, 'svc__kernel': 'rbf'}\n",
      "{'svc__C': 27.656874481703028, 'svc__gamma': 0.6848297385848633, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print('SVM')\n",
    "print(searches_svm[0].best_params_)\n",
    "print(searches_svm[1].best_params_)\n",
    "print(searches_svm[2].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred):\n",
    "    \"\"\"Computes confusion matrix, accuracy, precision, recall, specificity, f1-score, and AUC for true and predicted labels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : numpy.array\n",
    "        The true labels\n",
    "    y_pred : numpy.array\n",
    "        The predicted label\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        The first element is a confusion matrix, the second is a dictionary of remaining metrics\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(np.ravel(y_true), y_pred.astype('int32'))\n",
    "    acc = np.mean(y_true == y_pred.astype('int32'))\n",
    "    auc = roc_auc_score(np.ravel(y_true), y_pred.astype('int32'))\n",
    "    tn = cm[0,0]\n",
    "    fn = cm[1,0]\n",
    "    tp = cm[1,1]\n",
    "    fp = cm[0,1]\n",
    "    \n",
    "    if(tp + fp == 0):\n",
    "        precision = np.nan\n",
    "    else:\n",
    "        precision = tp/(tp + fp)\n",
    "        \n",
    "    if(tp + fn == 0):\n",
    "        recall = np.nan\n",
    "    else:\n",
    "        recall = tp/(tp + fn)\n",
    "    \n",
    "    if(tn + fp == 0):\n",
    "        specificity = np.nan\n",
    "    else:\n",
    "        specificity = tn/(tn + fp)\n",
    "        \n",
    "    if(precision + recall == 0):\n",
    "        f1 = np.nan\n",
    "    else:\n",
    "        f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "    \n",
    "    return((cm, {'Accuracy': [acc], 'AUC': [auc], 'Precision': [precision], 'Recall': [recall], 'Specificity': [specificity], 'F1-score': [f1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Iteration 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "====Done====\n"
     ]
    }
   ],
   "source": [
    "def get_classes(y_prob, threshold = .5):\n",
    "    return(np.array([1 if i > threshold else 0 for i in y_prob]))\n",
    "\n",
    "model_errs_tr = list()\n",
    "model_errs_val = list()\n",
    "model_epoch = list()\n",
    "\n",
    "errs_tr_myann = list()\n",
    "errs_val_myann = list()\n",
    "\n",
    "errs_tr_mlpc = list()\n",
    "errs_val_mlpc = list()\n",
    "\n",
    "errs_tr_svm = list()\n",
    "errs_val_svm = list()\n",
    "\n",
    "n_iter = 10\n",
    "n_folds = 10\n",
    "tuned_params = searches[0].best_params_\n",
    "tuned_params_sk = searches_sk[0].best_params_\n",
    "tuned_params_svm = searches_svm[0].best_params_\n",
    "\n",
    "scores_myanns = pd.DataFrame()\n",
    "scores_mlpcs = pd.DataFrame()\n",
    "scores_svms = pd.DataFrame()\n",
    "cms = dict()\n",
    "cms['MyANN'] = []\n",
    "cms['MLPC'] = []\n",
    "cms['SVM'] = []\n",
    "\n",
    "for i in range(n_iter):\n",
    "    #Retrain models using best parameters on all training set and compute testing metrics n_iter times\n",
    "    #Vary model initialization\n",
    "    print(\"======================\")\n",
    "    print(\"Iteration\", str(i + 1))\n",
    "    groups = splits.iloc[:,i].tolist()\n",
    "    group_kfold = GroupKFold(n_splits=n_folds)\n",
    "    scaler = StandardScaler(with_mean = False)\n",
    "    steps_myann = [('scaler', scaler), \n",
    "           ('my_ann', ANN(n_input = 20, n_hidden = tuned_params['my_ann__n_hidden'], act_h = tuned_params['my_ann__act_h'], momentum = tuned_params['my_ann__momentum'], learning_rate = tuned_params['my_ann__learning_rate'], seed = 123 + i, epochs = 100, quiet = True)\n",
    "        )]\n",
    "    steps_sk = [('scaler', scaler), \n",
    "           ('mlpc', MLPClassifier(batch_size = tuned_params_sk['mlpc__batch_size'], learning_rate_init = tuned_params_sk['mlpc__learning_rate_init'], momentum = tuned_params_sk['mlpc__momentum'], hidden_layer_sizes = tuned_params_sk['mlpc__hidden_layer_sizes'], activation = tuned_params_sk['mlpc__activation'], solver = 'sgd', learning_rate = 'constant', alpha = 0, random_state = 123 + i, max_iter = 100)\n",
    "        )]\n",
    "    steps_svm = [('scaler', scaler), \n",
    "           ('svc', svm.SVC(kernel = tuned_params_svm['svc__kernel'], gamma = tuned_params_svm['svc__gamma'], C = tuned_params_svm['svc__C'], random_state = 123 + i)\n",
    "        )]\n",
    "    steps_svm_proba = [('scaler', scaler), \n",
    "           ('svc', svm.SVC(kernel = tuned_params_svm['svc__kernel'], gamma = tuned_params_svm['svc__gamma'], C = tuned_params_svm['svc__C'], probability = True, random_state = 123 + i)\n",
    "        )]\n",
    "    \n",
    "    #Initialize pipelines\n",
    "    ann = Pipeline(steps_myann)\n",
    "    mlpc = Pipeline(steps_sk)\n",
    "    svc = Pipeline(steps_svm)\n",
    "    \n",
    "    #Fit models on all training and validation data\n",
    "    ann.fit(X_train, y_train, my_ann__nesterov = True)\n",
    "    mlpc.fit(X_train, np.ravel(y_train))\n",
    "    svc.fit(X_train, np.ravel(y_train))\n",
    "    \n",
    "    #Get predictions\n",
    "    y_hat_myann = get_classes(ann.predict(X_test))\n",
    "    y_hat_mlpc = mlpc.predict(X_test)\n",
    "    y_hat_svm = svc.predict(X_test)\n",
    "    \n",
    "    #Get scores\n",
    "    ann_cm, ann_scores = calc_metrics(np.ravel(y_test), y_hat_myann)\n",
    "    mlpc_cm, mlpc_scores = calc_metrics(np.ravel(y_test), y_hat_mlpc)\n",
    "    svm_cm, svm_scores = calc_metrics(np.ravel(y_test), y_hat_svm)\n",
    "    \n",
    "    cms['MyANN'].append(ann_cm)\n",
    "    cms['MLPC'].append(mlpc_cm)\n",
    "    cms['SVM'].append(svm_cm)\n",
    "    \n",
    "    scores_myanns = pd.concat([scores_myanns, pd.DataFrame(ann_scores)], axis = 0)\n",
    "    scores_mlpcs = pd.concat([scores_mlpcs, pd.DataFrame(mlpc_scores)], axis = 0)\n",
    "    scores_svms = pd.concat([scores_svms, pd.DataFrame(svm_scores)], axis = 0)\n",
    "    \n",
    "    for tr_index, val_index in group_kfold.split(X_train, y_train, groups):\n",
    "        #Cross-validate error for models using best parameters\n",
    "        #Vary model initialization at each outer iteration and training data at each inner iteration (fold)\n",
    "        #Folds used are the same as C5.0\n",
    "        \n",
    "        #Initialize pipelines\n",
    "        ann = Pipeline(steps_myann)\n",
    "        mlpc = Pipeline(steps_sk)\n",
    "        svc = Pipeline(steps_svm_proba)\n",
    "        \n",
    "        #Fit models on training data only\n",
    "        ann.fit(X_train[tr_index,:], y_train[tr_index,:], my_ann__nesterov = True, my_ann__xval = X_train[val_index,:], my_ann__yval = y_train[val_index,:])\n",
    "        mlpc.fit(X_train[tr_index,:], np.ravel(y_train[tr_index,:]))\n",
    "        svc.fit(X_train[tr_index,:], np.ravel(y_train[tr_index,:]))\n",
    "        \n",
    "        #Errors/epoch for my ann only\n",
    "        model_errs_tr.append(ann[-1].errs)\n",
    "        model_errs_val.append(ann[-1].errs_val)\n",
    "        model_epoch.append(np.arange(0, ann[-1].stop_epoch + 2).tolist())\n",
    "           \n",
    "        #Erros/fold for my ANN\n",
    "        errs_tr_myann.append(ann[-1].stop_err)\n",
    "        errs_val_myann.append(ann[-1].errs_val[-1])\n",
    "                \n",
    "        #Errors/fold for sklearn MLPC\n",
    "        y_hat_tr_mlpc = mlpc.predict_proba(X_train[tr_index,:])\n",
    "        y_hat_val_mlpc = mlpc.predict_proba(X_train[val_index,:])\n",
    "        errs_tr_mlpc.append(-inv_squared_diff(y_train[tr_index,:], y_hat_tr_mlpc))\n",
    "        errs_val_mlpc.append(-inv_squared_diff(y_train[val_index,:], y_hat_val_mlpc))\n",
    "        \n",
    "        #Errors/fold for svm\n",
    "        y_hat_tr_svm = svc.predict_proba(X_train[tr_index,:])\n",
    "        y_hat_val_svm = svc.predict_proba(X_train[val_index,:])\n",
    "        errs_tr_svm.append(-inv_squared_diff(y_train[tr_index,:], y_hat_tr_svm))\n",
    "        errs_val_svm.append(-inv_squared_diff(y_train[val_index,:], y_hat_val_svm))\n",
    "\n",
    "print(\"======================\")\n",
    "print(\"====Done====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get mean and sd of each testing metric (over 10 models) and append those of C5.0\n",
    "scores_myanns_stats = scores_myanns.describe()\n",
    "scores_mlpcs_stats = scores_mlpcs.describe()\n",
    "scores_svms_stats = scores_svms.describe()\n",
    "scores_myanns_stats_all = pd.concat([scores_myanns_stats.iloc[1,:], scores_myanns_stats.iloc[2,:]], axis = 1)\n",
    "scores_myanns_stats_all.columns = ['MyANN_mean', 'MyANN_sd']\n",
    "scores_mlpcs_stats_all = pd.concat([scores_mlpcs_stats.iloc[1,:], scores_mlpcs_stats.iloc[2,:]], axis = 1)\n",
    "scores_mlpcs_stats_all.columns = ['MLPC_mean', 'MLPC_sd']\n",
    "scores_svms_stats_all = pd.concat([scores_svms_stats.iloc[1,:], scores_svms_stats.iloc[2,:]], axis = 1)\n",
    "scores_svms_stats_all.columns = ['SVM_mean', 'SVM_sd']\n",
    "C5_res = pd.DataFrame({'C5_mean': [0.6345793,  0.6578815, 0.6782691, 0.6849358, 0.5718947, 0.6797293],\n",
    "                                      'C5_sd': [0.011881114, 0.006619025, 0.059239607, 0.012524511, 0.021594433, 0.026746076]\n",
    "                                     })\n",
    "C5_res.index = ['Accuracy', 'AUC', 'Precision', 'Recall', 'Specificity', 'F1-score']\n",
    "scores_agg = pd.concat([scores_myanns_stats_all,\n",
    "                        scores_mlpcs_stats_all,\n",
    "                        scores_svms_stats_all,\n",
    "                        C5_res], axis = 1)\n",
    "\n",
    "#Get errors of each model and erros/epoch of my ANN\n",
    "err_per_epoch = pd.DataFrame({'epoch': list(itertools.chain(*model_epoch)), 'train_error': list(itertools.chain(*model_errs_tr)), 'val_error': list(itertools.chain(*model_errs_val))})\n",
    "errs_myann = pd.DataFrame({'train_error': errs_tr_myann, 'val_error': errs_val_myann})\n",
    "errs_mlpc = pd.DataFrame({'train_error': errs_tr_mlpc, 'val_error': errs_val_mlpc})\n",
    "errs_svm = pd.DataFrame({'train_error': errs_tr_svm, 'val_error': errs_val_svm})\n",
    "\n",
    "#Get mean and sd of errors (over 100 models)\n",
    "err_per_epoch_agg = err_per_epoch.groupby('epoch').agg([np.nanmean, np.nanstd])\n",
    "errs_myann_agg = errs_myann.agg([np.nanmean, np.nanstd])\n",
    "errs_mlpc_agg = errs_mlpc.agg([np.nanmean, np.nanstd])\n",
    "errs_svm_agg = errs_svm.agg([np.nanmean, np.nanstd])\n",
    "errs_agg = pd.concat([errs_myann_agg.add_suffix('_myann'), errs_mlpc_agg.add_suffix('_mlpc'), errs_svm_agg.add_suffix('_svm')], axis = 1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MyANN_mean</th>\n",
       "      <th>MyANN_sd</th>\n",
       "      <th>MLPC_mean</th>\n",
       "      <th>MLPC_sd</th>\n",
       "      <th>SVM_mean</th>\n",
       "      <th>SVM_sd</th>\n",
       "      <th>C5_mean</th>\n",
       "      <th>C5_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.585260</td>\n",
       "      <td>0.085088</td>\n",
       "      <td>0.640462</td>\n",
       "      <td>0.008285</td>\n",
       "      <td>0.579961</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.634579</td>\n",
       "      <td>0.011881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.596696</td>\n",
       "      <td>0.052091</td>\n",
       "      <td>0.630110</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.575884</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.657882</td>\n",
       "      <td>0.006619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.683477</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>0.683621</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>0.644007</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.678269</td>\n",
       "      <td>0.059240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.520603</td>\n",
       "      <td>0.275550</td>\n",
       "      <td>0.698995</td>\n",
       "      <td>0.038539</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.684936</td>\n",
       "      <td>0.012525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.672789</td>\n",
       "      <td>0.175883</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.548753</td>\n",
       "      <td>1.170278e-16</td>\n",
       "      <td>0.571895</td>\n",
       "      <td>0.021594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.666225</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>0.690569</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.622837</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.679729</td>\n",
       "      <td>0.026746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MyANN_mean  MyANN_sd  MLPC_mean   MLPC_sd  SVM_mean  \\\n",
       "Accuracy       0.585260  0.085088   0.640462  0.008285  0.579961   \n",
       "AUC            0.596696  0.052091   0.630110  0.006422  0.575884   \n",
       "Precision      0.683477  0.014628   0.683621  0.008834  0.644007   \n",
       "Recall         0.520603  0.275550   0.698995  0.038539  0.603015   \n",
       "Specificity    0.672789  0.175883   0.561224  0.039583  0.548753   \n",
       "F1-score       0.666225  0.013330   0.690569  0.015774  0.622837   \n",
       "\n",
       "                   SVM_sd   C5_mean     C5_sd  \n",
       "Accuracy     0.000000e+00  0.634579  0.011881  \n",
       "AUC          0.000000e+00  0.657882  0.006619  \n",
       "Precision    0.000000e+00  0.678269  0.059240  \n",
       "Recall       0.000000e+00  0.684936  0.012525  \n",
       "Specificity  1.170278e-16  0.571895  0.021594  \n",
       "F1-score     0.000000e+00  0.679729  0.026746  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_error</th>\n",
       "      <th colspan=\"2\" halign=\"left\">val_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nanmean</th>\n",
       "      <th>nanstd</th>\n",
       "      <th>nanmean</th>\n",
       "      <th>nanstd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124996</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.124996</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.114449</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.125247</td>\n",
       "      <td>0.001357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111212</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.130025</td>\n",
       "      <td>0.015945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.110135</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.031505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.148373</td>\n",
       "      <td>0.052055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.104916</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.159892</td>\n",
       "      <td>0.049162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.104732</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.160723</td>\n",
       "      <td>0.049425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.104894</td>\n",
       "      <td>0.009846</td>\n",
       "      <td>0.159464</td>\n",
       "      <td>0.049747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.104987</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.158383</td>\n",
       "      <td>0.048185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.104757</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.160169</td>\n",
       "      <td>0.050223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_error           val_error          \n",
       "          nanmean    nanstd   nanmean    nanstd\n",
       "epoch                                          \n",
       "0        0.124996  0.000017  0.124996  0.000023\n",
       "1        0.114449  0.007463  0.125247  0.001357\n",
       "2        0.111212  0.007787  0.130025  0.015945\n",
       "3        0.110135  0.008146  0.137313  0.031505\n",
       "4        0.109375  0.009225  0.148373  0.052055\n",
       "...           ...       ...       ...       ...\n",
       "96       0.104916  0.009851  0.159892  0.049162\n",
       "97       0.104732  0.009872  0.160723  0.049425\n",
       "98       0.104894  0.009846  0.159464  0.049747\n",
       "99       0.104987  0.009788  0.158383  0.048185\n",
       "100      0.104757  0.009799  0.160169  0.050223\n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "err_per_epoch_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12c67cd60>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(err_per_epoch_agg.train_error.nanmean, color = 'blue', label = \"Training mean\")\n",
    "plt.plot(err_per_epoch_agg.train_error.nanmean + err_per_epoch_agg.train_error.nanstd, color = 'pink', label = \"Training sd\")\n",
    "plt.plot(err_per_epoch_agg.train_error.nanmean - err_per_epoch_agg.train_error.nanstd, color = 'pink')\n",
    "plt.plot(err_per_epoch_agg.val_error.nanmean, color = 'green', label = \"Validation mean\")\n",
    "plt.plot(err_per_epoch_agg.val_error.nanmean + err_per_epoch_agg.val_error.nanstd, color = 'yellow', label = \"Validation sd\")\n",
    "plt.plot(err_per_epoch_agg.val_error.nanmean - err_per_epoch_agg.val_error.nanstd, color = 'yellow')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nanmean</th>\n",
       "      <th>nanstd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_error_myann</th>\n",
       "      <td>0.105972</td>\n",
       "      <td>0.010655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_error_myann</th>\n",
       "      <td>0.158058</td>\n",
       "      <td>0.049396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_error_mlpc</th>\n",
       "      <td>2033.079385</td>\n",
       "      <td>64.550582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_error_mlpc</th>\n",
       "      <td>225.816542</td>\n",
       "      <td>7.334111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_error_svm</th>\n",
       "      <td>1911.171079</td>\n",
       "      <td>14.382303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_error_svm</th>\n",
       "      <td>206.574329</td>\n",
       "      <td>1.872679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nanmean     nanstd\n",
       "train_error_myann     0.105972   0.010655\n",
       "val_error_myann       0.158058   0.049396\n",
       "train_error_mlpc   2033.079385  64.550582\n",
       "val_error_mlpc      225.816542   7.334111\n",
       "train_error_svm    1911.171079  14.382303\n",
       "val_error_svm       206.574329   1.872679"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
